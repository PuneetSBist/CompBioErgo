Default LossFunc
Original With EarlySTopping
Step LR params: step5, gamma:0.5
kfold: 1
Using Training set C:\Users\bistp\Downloads\CLass\CompBio\Project\Python\CompBioErgo_Copy\CompBioErgo\proj_data\BAP\epi_split\train.csv and test C:\Users\bistp\Downloads\CLass\CompBio\Project\Python\CompBioErgo_Copy\CompBioErgo\proj_data\BAP\epi_split\test.csv
should enbale GPU?  True
Params:  {'lr': 0.0001, 'wd': 0, 'epochs': 100, 'batch_size': 64, 'patience': 10, 'model_save_occur': 30, 'lstm_dim': 512, 'emb_dim': 16, 'dropout': 0.2, 'option': 0, 'enc_dim': 100, 'train_ae': True}
Using test for early stopping
C:\Users\bistp\anaconda3\envs\TryCuda3_11\Lib\site-packages\torch\nn\modules\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
Using 2 Trans Encoder with head 4 and dropout 0.2
epoch: 1
train_auc:0.7317344642303305, train_acc:0.6652537277537277, train_prec:0.7285947223054141, train_recall:0.5266196048248409, train_f1:0.611357369725315, train_thresh:0.5
val_auc:0.7182915034567889, val_acc:0.6602889544058819, val_prec:0.7171663571239055, val_recall:0.5291569803009911, val_f1:0.6089809482236648, val_thresh:0.5
Best Model saved at epoch 1 to 2024-12-12_18-12\lstmT_psb_checkpoints_best.pt with thres0.5
one epoch time: 153.2528109550476
epoch: 2
train_auc:0.7608739538677425, train_acc:0.6820045695045696, train_prec:0.7802637427767076, train_recall:0.5066323524106165, train_f1:0.6143570673374895, train_thresh:0.5
val_auc:0.7293631166266293, val_acc:0.6630170167476114, val_prec:0.7670958167889945, val_recall:0.4680288755658877, val_f1:0.5813550563846925, val_thresh:0.5
Best Model saved at epoch 2 to 2024-12-12_18-12\lstmT_psb_checkpoints_best.pt with thres0.5
one epoch time: 160.44078373908997
epoch: 3
train_auc:0.7794221580731625, train_acc:0.7008237133237133, train_prec:0.7729427534573512, train_recall:0.5686385337871153, train_f1:0.6552342943454794, train_thresh:0.5
val_auc:0.7285239572564157, val_acc:0.6641914292355309, val_prec:0.7347331583552056, val_recall:0.5137648354337453, val_f1:0.6046947004608295, val_thresh:0.5
Best Model saved at epoch 3 to 2024-12-12_18-12\lstmT_psb_checkpoints_best.pt with thres0.5
one epoch time: 169.49166226387024
epoch: 4
train_auc:0.7924118550174812, train_acc:0.7123075998075998, train_prec:0.7300894183894262, train_recall:0.6735896479982683, train_f1:0.700702441343333, train_thresh:0.5
val_auc:0.7302826963207156, val_acc:0.6623931101134042, val_prec:0.6889382547277284, val_recall:0.5919491006974184, val_f1:0.6367716545796754, val_thresh:0.5
one epoch time: 168.43391489982605
epoch: 5
train_auc:0.7987710325846854, train_acc:0.7162457912457912, train_prec:0.7284532598061015, train_recall:0.6894519740718916, train_f1:0.7084162269699853, train_thresh:0.5
val_auc:0.7405143033574666, val_acc:0.6701124255287915, val_prec:0.6867793694734862, val_recall:0.6253028263795424, val_f1:0.6546008812378318, val_thresh:0.5
Best Model saved at epoch 5 to 2024-12-12_18-12\lstmT_psb_checkpoints_best.pt with thres0.5
one epoch time: 169.68617129325867
epoch: 6
train_auc:0.8095919006728806, train_acc:0.7280663780663781, train_prec:0.7744727662222994, train_recall:0.6434644570851322, train_f1:0.7029164477141355, train_thresh:0.5
val_auc:0.74858134982048, val_acc:0.6778072740173471, val_prec:0.7317656818326845, val_recall:0.5612382234185733, val_f1:0.635256969545889, val_thresh:0.5
Best Model saved at epoch 6 to 2024-12-12_18-12\lstmT_psb_checkpoints_best.pt with thres0.5
one epoch time: 164.07284903526306
epoch: 7
train_auc:0.8149167957563742, train_acc:0.732912457912458, train_prec:0.7659329039700087, train_recall:0.6707635322838623, train_f1:0.7151961224306616, train_thresh:0.5
val_auc:0.7469815411739242, val_acc:0.6769142311879917, val_prec:0.7234641189747395, val_recall:0.5725926832252539, val_f1:0.6392470768222053, val_thresh:0.5
one epoch time: 162.41316866874695
epoch: 8
train_auc:0.8195130222458873, train_acc:0.7361712361712361, train_prec:0.7583648013894189, train_recall:0.6931559895614109, train_f1:0.7242956596044133, train_thresh:0.5
val_auc:0.7518046145158552, val_acc:0.6796912273833845, val_prec:0.7101030337721809, val_recall:0.6071454790162731, val_f1:0.6546006200118726, val_thresh:0.5
Best Model saved at epoch 8 to 2024-12-12_18-12\lstmT_psb_checkpoints_best.pt with thres0.5
one epoch time: 164.0965449810028
epoch: 9
train_auc:0.8232151161338441, train_acc:0.7396103896103896, train_prec:0.7924060293837054, train_recall:0.6492730268300603, train_f1:0.7137342516822442, train_thresh:0.5
val_auc:0.7546819668487157, val_acc:0.6816852819201644, val_prec:0.7346442006765087, val_recall:0.568677352257433, val_f1:0.6410935474082043, val_thresh:0.5
Best Model saved at epoch 9 to 2024-12-12_18-12\lstmT_psb_checkpoints_best.pt with thres0.5
one epoch time: 165.34780097007751
epoch: 10
train_auc:0.8268577051545755, train_acc:0.7420574795574796, train_prec:0.7977218934911242, train_recall:0.6485153872981131, train_f1:0.7154219153184348, train_thresh:0.5
val_auc:0.7554397968746063, val_acc:0.6797646281638795, val_prec:0.7330392841276893, val_recall:0.5653003792976875, val_f1:0.6383343234916204, val_thresh:0.5
one epoch time: 165.24411535263062
epoch: 11
train_auc:0.8332570645687034, train_acc:0.7487373737373737, train_prec:0.7835762570100506, train_recall:0.6872512116219499, train_f1:0.7322595525486276, train_thresh:0.5
val_auc:0.7606094440657807, val_acc:0.6837282703106077, val_prec:0.7163860701107011, val_recall:0.6080998409396794, val_f1:0.6578163673183064, val_thresh:0.5
Best Model saved at epoch 11 to 2024-12-12_18-12\lstmT_psb_checkpoints_best.pt with thres0.5
one epoch time: 164.32066535949707
epoch: 12
train_auc:0.8350128443809053, train_acc:0.7486712361712362, train_prec:0.8102920431011196, train_recall:0.6493211309273267, train_f1:0.7209303878173673, train_thresh:0.5
val_auc:0.7534467095246612, val_acc:0.6814895465055112, val_prec:0.755047985965395, val_recall:0.5371344671479261, val_f1:0.6277167696179364, val_thresh:0.5
one epoch time: 163.88953757286072
epoch: 13
train_auc:0.8385784371739022, train_acc:0.7532888407888408, train_prec:0.7904426975589574, train_recall:0.6892715837071423, train_f1:0.7363985018919075, train_thresh:0.5
val_auc:0.7582830892258736, val_acc:0.6822724881641241, val_prec:0.7180590939705409, val_recall:0.6000489416370978, val_f1:0.653771296024742, val_thresh:0.5
one epoch time: 164.69167733192444
epoch: 14
train_auc:0.8406275682844199, train_acc:0.7536916786916787, train_prec:0.8301482211892128, train_recall:0.6378483037292701, train_f1:0.7214031174342374, train_thresh:0.5
val_auc:0.7570073064112544, val_acc:0.6814406126518479, val_prec:0.7705193241122587, val_recall:0.5166523920225131, val_f1:0.6185509624117423, val_thresh:0.5
one epoch time: 165.45142602920532
epoch: 15
train_auc:0.8425075409785787, train_acc:0.7570286195286196, train_prec:0.7913247362250879, train_recall:0.6981107115798588, train_f1:0.7418008957836829, train_thresh:0.5
val_auc:0.7590493665270845, val_acc:0.6841075076764983, val_prec:0.7225230022780391, val_recall:0.5976263306007586, val_f1:0.6541665550585273, val_thresh:0.5
Best Model saved at epoch 15 to 2024-12-12_18-12\lstmT_psb_checkpoints_best.pt with thres0.5
one epoch time: 165.13724613189697
epoch: 16
train_auc:0.84615251887873, train_acc:0.7606541606541607, train_prec:0.7955193149433437, train_recall:0.7016102846559956, train_f1:0.7456195284043708, train_thresh:0.5
val_auc:0.7576477614537819, val_acc:0.6837772041642709, val_prec:0.7233460257020466, val_recall:0.5950324238345772, val_f1:0.6529450463876694, val_thresh:0.5
one epoch time: 166.9221796989441
epoch: 17
epoch: 19
train_auc:0.8509502098703774, train_acc:0.7648629148629149, train_prec:0.8142704245451302, train_recall:0.6862049475064038, train_f1:0.7447724958884799, train_thresh:0.5
val_auc:0.7567658580682827, val_acc:0.6824559901153615, val_prec:0.7397247057310092, val_recall:0.5628532974427994, val_f1:0.6392807015105824, val_thresh:0.5
one epoch time: 167.49880409240723
epoch: 20
train_auc:0.8521693211716296, train_acc:0.7656746031746032, train_prec:0.8277059102777119, train_recall:0.6709800007215615, train_f1:0.7411481060832487, train_thresh:0.5
val_auc:0.7603395948948718, val_acc:0.6841197411399141, val_prec:0.7499667685763658, val_recall:0.5522574330111342, val_f1:0.6361035556745634, val_thresh:0.5
Best Model saved at epoch 20 to 2024-12-12_18-12\lstmT_psb_checkpoints_best.pt with thres0.5
one epoch time: 175.39616584777832
epoch: 21
train_auc:0.8536437414394152, train_acc:0.7676647426647427, train_prec:0.813727286823891, train_recall:0.694202253676957, train_f1:0.7492277340809387, train_thresh:0.5
val_auc:0.7587459572310697, val_acc:0.6826884259202622, val_prec:0.7309751493207068, val_recall:0.5780007341245564, val_f1:0.6455492087785947, val_thresh:0.5
one epoch time: 170.13660836219788
epoch: 22
train_auc:0.8544068320643641, train_acc:0.7682118807118807, train_prec:0.8279558823529412, train_recall:0.6770771950500883, train_f1:0.7449537885453812, train_thresh:0.5
val_auc:0.7580006852763057, val_acc:0.682064519286055, val_prec:0.746193565470674, val_recall:0.551670133365961, val_f1:0.6343542918243595, val_thresh:0.5
one epoch time: 169.5603096485138
epoch: 23
train_auc:0.8551554208081259, train_acc:0.7693783068783069, train_prec:0.8101528747092057, train_recall:0.703594578668238, train_f1:0.7531232099067382, train_thresh:0.5
val_auc:0.7579567481903863, val_acc:0.6816118811396694, val_prec:0.7273758082804694, val_recall:0.5808148782576777, val_f1:0.6458854903668226, val_thresh:0.5
one epoch time: 175.0411672592163
epoch: 24
train_auc:0.8562821548991926, train_acc:0.7701659451659452, train_prec:0.8093166076862702, train_recall:0.7068295792094091, train_f1:0.7546091824157765, train_thresh:0.5
val_auc:0.7584422567013049, val_acc:0.682211320847045, val_prec:0.724162852324741, val_recall:0.5884742444634773, val_f1:0.6493054149285165, val_thresh:0.5
one epoch time: 160.2640838623047
epoch: 25
train_auc:0.8567193169410334, train_acc:0.7706830206830206, train_prec:0.815239162406331, train_recall:0.6999627193246185, train_f1:0.7532158293863395, train_thresh:0.5
val_auc:0.7578129490570752, val_acc:0.6818932507982335, val_prec:0.7291538176884175, val_recall:0.5786125045882785, val_f1:0.6452185065422346, val_thresh:0.5
one epoch time: 160.64592480659485
epoch: 26
train_auc:0.8576410939840603, train_acc:0.7711099086099086, train_prec:0.8223232669869595, train_recall:0.6916166584488834, train_f1:0.7513276590741333, train_thresh:0.5
val_auc:0.7579429826814932, val_acc:0.6820889862128867, val_prec:0.7371827573013646, val_recall:0.5657897956686652, val_f1:0.6402137645544034, val_thresh:0.5
one epoch time: 162.91988396644592
epoch: 27
train_auc:0.8580241939371245, train_acc:0.7718674843674843, train_prec:0.8187574031248237, train_recall:0.6982670498959749, train_f1:0.7537272261129754, train_thresh:0.5
val_auc:0.7585481394751892, val_acc:0.68243152318853, val_prec:0.7291397651109881, val_recall:0.580349932705249, val_f1:0.6462917796460056, val_thresh:0.5
one epoch time: 165.99719309806824
epoch: 28
train_auc:0.858443699556512, train_acc:0.7721620971620972, train_prec:0.8076541363605465, train_recall:0.7144300265775138, train_f1:0.7581872016744519, train_thresh:0.5
val_auc:0.7582550658344815, val_acc:0.6820278188958075, val_prec:0.7161836099886625, val_recall:0.602863085770219, val_f1:0.654655612244898, val_thresh:0.5
one epoch time: 164.70711135864258
epoch: 29
train_auc:0.8588031126505545, train_acc:0.7722162097162097, train_prec:0.8207220994161991, train_recall:0.696547328418698, train_f1:0.7535534233208652, train_thresh:0.5
val_auc:0.7580614064655341, val_acc:0.6817953830909068, val_prec:0.7292142460341954, val_recall:0.5781965006729475, val_f1:0.6449834168179399, val_thresh:0.5
one epoch time: 167.9917552471161
epoch: 30
train_auc:0.8592091627209775, train_acc:0.7728835978835978, train_prec:0.8226469291696884, train_recall:0.6957175327408512, train_f1:0.7538768276473194, train_thresh:0.5
val_auc:0.758644601301206, val_acc:0.682211320847045, val_prec:0.7322910815702428, val_recall:0.5742566988865777, val_f1:0.6437163116676496, val_thresh:0.5
Model saved at epoch 30 to 2024-12-12_18-12\lstmT_psb_checkpoints_epoch_30
one epoch time: 162.49537992477417
Early stopping triggered at epoch 30 with no improvement in AUC
Best Model was at epoch 20
C:\Users\bistp\anaconda3\envs\TryCuda3_11\Lib\site-packages\torch\nn\modules\rnn.py:1135: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at C:\cb\pytorch_1000000000000\work\aten\src\ATen\native\cudnn\RNN.cpp:1410.)
  result = _VF.lstm(
kfold:11 test_auc:0.7603395948948718, test_acc:0.6841197411399141, test_prec:0.7499667685763658, test_recall:0.5522574330111342, test_f1:0.6361035556745634, test_thresh:0.5
(TryCuda3_11) PS C:\Users\bistp\Downloads\CLass\CompBio\Project\Python\CompBioErgo_Copy\CompBioErgo> 


